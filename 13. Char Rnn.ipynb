{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have created an Char-rnn model to write a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice's adventures in wonderland\n",
      "\n",
      "lewis carroll\n",
      "\n",
      "the millennium fulcrum edition 3.0\n",
      "\n",
      "chapter i. down the rabbit-hole\n",
      "\n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of\n"
     ]
    }
   ],
   "source": [
    "raw_text = open('C:/Users/Shaurya/summer/keras/wonderland.txt').read()\n",
    "raw_text = raw_text.lower()\n",
    "print (raw_text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 144413\n",
      "Total Vocab: 45\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters:\", n_chars)\n",
    "print (\"Total Vocab:\", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "step = 1\n",
    "\n",
    "inp_chars=[]\n",
    "out_chars=[]\n",
    "\n",
    "for i in range(0, (n_chars-seq_len), step):\n",
    "    inp_chars.append(raw_text[i:i+seq_len])\n",
    "    out_chars.append(raw_text[i+seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice's ad -> v\n",
      "lice's adv -> e\n",
      "ice's adve -> n\n",
      "ce's adven -> t\n",
      "e's advent -> u\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    print(inp_chars[j] + ' -> ' + out_chars[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patterns:  144403\n"
     ]
    }
   ],
   "source": [
    "print('Total patterns: ',len(inp_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for k in range(len(inp_chars)):\n",
    "    X.append([char_to_int[l] for l in inp_chars[k]])\n",
    "    y.append([char_to_int[m] for m in out_chars[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 30, 27, 21, 23, 4, 37, 1, 19, 22]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape dataX to size of [samples, time steps, features] and scale it to 0-1\n",
    "# Represent dataY as one hot encoding\n",
    "X_train = np.reshape(X, (len(X), seq_len, 1))/float(n_vocab)\n",
    "y_train = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144403, 45)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144403, 10, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_5 (SimpleRNN)     (None, 128)               16640     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 45)                5805      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 45)                0         \n",
      "=================================================================\n",
      "Total params: 22,445.0\n",
      "Trainable params: 22,445.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, return_sequences=False,input_shape=( seq_len, 1)))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 115522 samples, validate on 28881 samples\n",
      "Epoch 1/30\n",
      "115522/115522 [==============================] - 23s - loss: 2.9149 - acc: 0.1974 - val_loss: 2.8551 - val_acc: 0.2197\n",
      "Epoch 2/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.7834 - acc: 0.2281 - val_loss: 2.7666 - val_acc: 0.2364\n",
      "Epoch 3/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.7129 - acc: 0.2425 - val_loss: 2.7072 - val_acc: 0.2488\n",
      "Epoch 4/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.6654 - acc: 0.2548 - val_loss: 2.6758 - val_acc: 0.2511\n",
      "Epoch 5/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.6273 - acc: 0.2627 - val_loss: 2.6411 - val_acc: 0.2549\n",
      "Epoch 6/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.5940 - acc: 0.2679 - val_loss: 2.6299 - val_acc: 0.2646\n",
      "Epoch 7/30\n",
      "115522/115522 [==============================] - 25s - loss: 2.5639 - acc: 0.2737 - val_loss: 2.5931 - val_acc: 0.2732\n",
      "Epoch 8/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.5354 - acc: 0.2812 - val_loss: 2.5729 - val_acc: 0.2690\n",
      "Epoch 9/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.5115 - acc: 0.2863 - val_loss: 2.5562 - val_acc: 0.2810\n",
      "Epoch 10/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.4881 - acc: 0.2933 - val_loss: 2.5407 - val_acc: 0.2845\n",
      "Epoch 11/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.4671 - acc: 0.2987 - val_loss: 2.5225 - val_acc: 0.2866\n",
      "Epoch 12/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.4473 - acc: 0.3047 - val_loss: 2.5007 - val_acc: 0.2953\n",
      "Epoch 13/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.4272 - acc: 0.3092 - val_loss: 2.5071 - val_acc: 0.2989\n",
      "Epoch 14/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.4098 - acc: 0.3155 - val_loss: 2.4814 - val_acc: 0.3027\n",
      "Epoch 15/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.3908 - acc: 0.3195 - val_loss: 2.4756 - val_acc: 0.3091\n",
      "Epoch 16/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.3732 - acc: 0.3250 - val_loss: 2.4545 - val_acc: 0.3123\n",
      "Epoch 17/30\n",
      "115522/115522 [==============================] - 23s - loss: 2.3585 - acc: 0.3279 - val_loss: 2.4524 - val_acc: 0.3108\n",
      "Epoch 18/30\n",
      "115522/115522 [==============================] - 23s - loss: 2.3441 - acc: 0.3321 - val_loss: 2.4354 - val_acc: 0.3134\n",
      "Epoch 19/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.3311 - acc: 0.3360 - val_loss: 2.4166 - val_acc: 0.3210\n",
      "Epoch 20/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.3180 - acc: 0.3394 - val_loss: 2.4312 - val_acc: 0.3181\n",
      "Epoch 21/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.3064 - acc: 0.3435 - val_loss: 2.4182 - val_acc: 0.3230\n",
      "Epoch 22/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.2943 - acc: 0.3474 - val_loss: 2.4048 - val_acc: 0.3278\n",
      "Epoch 23/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.2847 - acc: 0.3484 - val_loss: 2.3951 - val_acc: 0.3296\n",
      "Epoch 24/30\n",
      "115522/115522 [==============================] - 23s - loss: 2.2749 - acc: 0.3507 - val_loss: 2.3926 - val_acc: 0.3308\n",
      "Epoch 25/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.2661 - acc: 0.3529 - val_loss: 2.3911 - val_acc: 0.3305\n",
      "Epoch 26/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.2585 - acc: 0.3545 - val_loss: 2.3858 - val_acc: 0.3327\n",
      "Epoch 27/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.2492 - acc: 0.3578 - val_loss: 2.4040 - val_acc: 0.3287\n",
      "Epoch 28/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.2434 - acc: 0.3595 - val_loss: 2.3821 - val_acc: 0.3331\n",
      "Epoch 29/30\n",
      "115522/115522 [==============================] - 23s - loss: 2.2355 - acc: 0.3614 - val_loss: 2.3828 - val_acc: 0.3326\n",
      "Epoch 30/30\n",
      "115522/115522 [==============================] - 22s - loss: 2.2299 - acc: 0.3629 - val_loss: 2.3608 - val_acc: 0.3390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6e0633b710>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" rge kitche \"\n",
      "\n",
      "Generated Sequence:\n",
      "[36, 25, 23, 1, 29, 27, 38, 21, 26, 23]\n",
      "25\n",
      "g[25, 23, 1, 29, 27, 38, 21, 26, 23, 25]\n",
      "1\n",
      " [23, 1, 29, 27, 38, 21, 26, 23, 25, 1]\n",
      "38\n",
      "t[1, 29, 27, 38, 21, 26, 23, 25, 1, 38]\n",
      "26\n",
      "h[29, 27, 38, 21, 26, 23, 25, 1, 38, 26]\n",
      "23\n",
      "e[27, 38, 21, 26, 23, 25, 1, 38, 26, 23]\n",
      "1\n",
      " [38, 21, 26, 23, 25, 1, 38, 26, 23, 1]\n",
      "25\n",
      "g[21, 26, 23, 25, 1, 38, 26, 23, 1, 25]\n",
      "33\n",
      "o[26, 23, 25, 1, 38, 26, 23, 1, 25, 33]\n",
      "33\n",
      "o[23, 25, 1, 38, 26, 23, 1, 25, 33, 33]\n",
      "37\n",
      "s[25, 1, 38, 26, 23, 1, 25, 33, 33, 37]\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "start = np.random.randint(0, len(X_train)-1)\n",
    "pattern = X[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "print (\"\\nGenerated Sequence:\")\n",
    "print(pattern)\n",
    "for i in range(10):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x/float(n_vocab)\n",
    "    prediction = model.predict(x)\n",
    "    index = np.argmax(prediction)\n",
    "    print(index)\n",
    "    result = int_to_char[index]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    print(pattern)\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ir\n",
      "doesn't \"\n",
      "\n",
      "Generated Sequence:\n",
      " kev the whnt to she whst ane she whnt to she whst\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(X_train)-1)\n",
    "pattern = X[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "print (\"\\nGenerated Sequence:\")\n",
    "#print(pattern)\n",
    "for i in range(50):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x/float(n_vocab)\n",
    "    prediction = model.predict(x)\n",
    "    index = np.argmax(prediction)\n",
    "    #print(index)\n",
    "    result = int_to_char[index]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "   # print(pattern)\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2 = np.reshape(X, (len(X), seq_len))/float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 10, 32)            1440      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               295936    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 45)                11565     \n",
      "=================================================================\n",
      "Total params: 308,941.0\n",
      "Trainable params: 308,941\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(n_vocab, embedding_vector_length, input_length=seq_len))\n",
    "model2.add(LSTM(256))\n",
    "model2.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 115522 samples, validate on 28881 samples\n",
      "Epoch 1/10\n",
      "115522/115522 [==============================] - 197s - loss: 3.0404 - val_loss: 3.0514:\n",
      "Epoch 2/10\n",
      "115522/115522 [==============================] - 197s - loss: 3.0299 - val_loss: 3.0455\n",
      "Epoch 3/10\n",
      "115522/115522 [==============================] - 187s - loss: 3.0286 - val_loss: 3.0472\n",
      "Epoch 4/10\n",
      "115522/115522 [==============================] - 194s - loss: 3.0281 - val_loss: 3.0460\n",
      "Epoch 5/10\n",
      "115522/115522 [==============================] - 198s - loss: 3.0276 - val_loss: 3.0458s \n",
      "Epoch 6/10\n",
      "115522/115522 [==============================] - 190s - loss: 3.0269 - val_loss: 3.0497\n",
      "Epoch 7/10\n",
      "115522/115522 [==============================] - 182s - loss: 3.0269 - val_loss: 3.0478\n",
      "Epoch 8/10\n",
      "115522/115522 [==============================] - 181s - loss: 3.0268 - val_loss: 3.0484\n",
      "Epoch 9/10\n",
      "115522/115522 [==============================] - 181s - loss: 3.0268 - val_loss: 3.0455\n",
      "Epoch 10/10\n",
      "115522/115522 [==============================] - 183s - loss: 3.0265 - val_loss: 3.0473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6e17441eb8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train2, y_train, epochs=10, batch_size=64, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" s:\n",
      "you'd b \"\n",
      "\n",
      "Generated Sequence:\n",
      "1\n",
      " \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(X_train)-1)\n",
    "pattern = X[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "print (\"\\nGenerated Sequence:\")\n",
    "#print(pattern)\n",
    "for i in range(1):\n",
    "    x = np.reshape(pattern, (1, len(pattern)))\n",
    "    x = x/float(n_vocab)\n",
    "    prediction = model2.predict(x)\n",
    "    index = np.argmax(prediction)\n",
    "    print(index)\n",
    "    result = int_to_char[index]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "   # print(pattern)\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  young lad \"\n",
      "1\n",
      " [43, 33, 39, 32, 25, 1, 30, 19, 22, 1]\n",
      "1\n",
      " [33, 39, 32, 25, 1, 30, 19, 22, 1, 1]\n",
      "1\n",
      " [39, 32, 25, 1, 30, 19, 22, 1, 1, 1]\n",
      "1\n",
      " [32, 25, 1, 30, 19, 22, 1, 1, 1, 1]\n",
      "1\n",
      " [25, 1, 30, 19, 22, 1, 1, 1, 1, 1]\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(X_train)-1)\n",
    "pattern = X[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "for i in range(5):\n",
    "    x = np.reshape(pattern, (1, len(pattern)))\n",
    "    x = x/float(n_vocab)\n",
    "    prediction = model2.predict(x)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    print(pattern)\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the effects of Learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I study how choosing the different learning rates effect the performance of my model. I have noticed that the choosing lower learning rates improve the accuracy but a very small learning rate also degrade the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracies=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate :0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s - loss: 14.5131 - acc: 0.0985 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s - loss: 14.5553 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s - loss: 14.5550 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5557 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5553 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5557 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5560 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5567 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5560 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5550 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5550 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5560 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5553 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5546 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5557 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 4s - loss: 14.5560 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 4s - loss: 14.5553 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 4s - loss: 14.5553 - acc: 0.0970 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 4s - loss: 14.5557 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s - loss: 14.5557 - acc: 0.0969 - val_loss: 14.5090 - val_acc: 0.0998\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "OPTIMIZER = Adam( lr=0.1)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,batch_size=64, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s\n",
      "Loss: 14.55, Accuracy: 9.74%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Learning rate :0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.4517 - acc: 0.8658 - val_loss: 0.2159 - val_acc: 0.9378\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.3457 - acc: 0.9057 - val_loss: 0.1909 - val_acc: 0.9485\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.3104 - acc: 0.9158 - val_loss: 0.2002 - val_acc: 0.9459\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.3183 - acc: 0.9155 - val_loss: 0.1958 - val_acc: 0.9507\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.3043 - acc: 0.9217 - val_loss: 0.1804 - val_acc: 0.9544\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.3110 - acc: 0.9249 - val_loss: 0.1904 - val_acc: 0.9512\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2816 - acc: 0.9296 - val_loss: 0.1768 - val_acc: 0.9541\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.3025 - acc: 0.9256 - val_loss: 0.1743 - val_acc: 0.9569\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2812 - acc: 0.9308 - val_loss: 0.1814 - val_acc: 0.9551\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2719 - acc: 0.9322 - val_loss: 0.1756 - val_acc: 0.9571\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2751 - acc: 0.9324 - val_loss: 0.2010 - val_acc: 0.9556\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2667 - acc: 0.9351 - val_loss: 0.1878 - val_acc: 0.9563\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2811 - acc: 0.9326 - val_loss: 0.1825 - val_acc: 0.9576\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2773 - acc: 0.9336 - val_loss: 0.1912 - val_acc: 0.9585\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2716 - acc: 0.9346 - val_loss: 0.2114 - val_acc: 0.9533\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2708 - acc: 0.9355 - val_loss: 0.1802 - val_acc: 0.9594\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2677 - acc: 0.9373 - val_loss: 0.1876 - val_acc: 0.9579\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2685 - acc: 0.9370 - val_loss: 0.1935 - val_acc: 0.9590\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2727 - acc: 0.9361 - val_loss: 0.1895 - val_acc: 0.9594\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2567 - acc: 0.9381 - val_loss: 0.1907 - val_acc: 0.9578\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_shape=(784,)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.summary()\n",
    "\n",
    "OPTIMIZER = Adam( lr=0.01)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train, Y_train,batch_size=64, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9664/10000 [===========================>..] - ETA: 0s\n",
      "Loss: 0.19, Accuracy: 95.88%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model2.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate :0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.4417 - acc: 0.8679 - val_loss: 0.1595 - val_acc: 0.9557\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2083 - acc: 0.9377 - val_loss: 0.1221 - val_acc: 0.9638\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.1617 - acc: 0.9516 - val_loss: 0.1126 - val_acc: 0.9657\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.1359 - acc: 0.9587 - val_loss: 0.1006 - val_acc: 0.9708\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.1193 - acc: 0.9627 - val_loss: 0.0977 - val_acc: 0.9702\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.1062 - acc: 0.9683 - val_loss: 0.0897 - val_acc: 0.9723\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0959 - acc: 0.9701 - val_loss: 0.0858 - val_acc: 0.9753\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0901 - acc: 0.9721 - val_loss: 0.0870 - val_acc: 0.9756\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.0855 - acc: 0.9734 - val_loss: 0.0861 - val_acc: 0.9750\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0803 - acc: 0.9749 - val_loss: 0.0894 - val_acc: 0.9741\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0762 - acc: 0.9761 - val_loss: 0.0817 - val_acc: 0.9777\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0748 - acc: 0.9765 - val_loss: 0.0822 - val_acc: 0.9759\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.0677 - acc: 0.9785 - val_loss: 0.0783 - val_acc: 0.9778\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0653 - acc: 0.9793 - val_loss: 0.0882 - val_acc: 0.9752\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0648 - acc: 0.9791 - val_loss: 0.0793 - val_acc: 0.9782\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0600 - acc: 0.9808 - val_loss: 0.0781 - val_acc: 0.9794\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0587 - acc: 0.9809 - val_loss: 0.0855 - val_acc: 0.9771\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0592 - acc: 0.9803 - val_loss: 0.0827 - val_acc: 0.9784\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.0543 - acc: 0.9826 - val_loss: 0.0855 - val_acc: 0.9775\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.0524 - acc: 0.9830 - val_loss: 0.0794 - val_acc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(128, input_shape=(784,)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "model3.summary()\n",
    "\n",
    "OPTIMIZER = Adam( lr=0.001)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model3.fit(X_train, Y_train,batch_size=64, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8896/10000 [=========================>....] - ETA: 0s\n",
      "Loss: 0.08, Accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model3.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Learning rate :0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s - loss: 1.1343 - acc: 0.6499 - val_loss: 0.4058 - val_acc: 0.8930\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.4924 - acc: 0.8542 - val_loss: 0.2879 - val_acc: 0.9174\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.3848 - acc: 0.8860 - val_loss: 0.2419 - val_acc: 0.9310\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.3266 - acc: 0.9029 - val_loss: 0.2113 - val_acc: 0.9380\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2920 - acc: 0.9138 - val_loss: 0.1888 - val_acc: 0.9448\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2600 - acc: 0.9239 - val_loss: 0.1741 - val_acc: 0.9487\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2367 - acc: 0.9306 - val_loss: 0.1612 - val_acc: 0.9523\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2220 - acc: 0.9352 - val_loss: 0.1511 - val_acc: 0.9553\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.2061 - acc: 0.9392 - val_loss: 0.1439 - val_acc: 0.9568\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.1933 - acc: 0.9428 - val_loss: 0.1377 - val_acc: 0.9590\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.1826 - acc: 0.9450 - val_loss: 0.1326 - val_acc: 0.9598\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1711 - acc: 0.9498 - val_loss: 0.1261 - val_acc: 0.9623\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1620 - acc: 0.9525 - val_loss: 0.1210 - val_acc: 0.9647\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1552 - acc: 0.9531 - val_loss: 0.1180 - val_acc: 0.9653\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.1489 - acc: 0.9543 - val_loss: 0.1148 - val_acc: 0.9671\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1422 - acc: 0.9587 - val_loss: 0.1120 - val_acc: 0.9673\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1383 - acc: 0.9589 - val_loss: 0.1087 - val_acc: 0.9679\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1325 - acc: 0.9607 - val_loss: 0.1066 - val_acc: 0.9688\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1284 - acc: 0.9611 - val_loss: 0.1047 - val_acc: 0.9698\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1227 - acc: 0.9637 - val_loss: 0.1022 - val_acc: 0.9694\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(128, input_shape=(784,)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(128))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n",
    "model4.summary()\n",
    "\n",
    "OPTIMIZER = Adam( lr=0.0001)\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model4.fit(X_train, Y_train,batch_size=64, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9568/10000 [===========================>..] - ETA: 0s\n",
      "Loss: 0.10, Accuracy: 97.14%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model4.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ploting the graph to see the effects of learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0974, 0.95879999999999999, 0.9798, 0.97140000000000004]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrates=[0.1,0.01,0.001,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAeWcc0g/2bXSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcf21c8c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(lrates,accuracies)\n",
    "\n",
    "plt.title('learning rates accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the effect of different values of dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have studied the effect of different values of dropout. I noticed that choosing low value of dropout doesn't solve the problem of overfitting and choosing a very high value, We lost too much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracies=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.3968 - acc: 0.8839 - val_loss: 0.1634 - val_acc: 0.9525\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1619 - acc: 0.9522 - val_loss: 0.1224 - val_acc: 0.9629\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1170 - acc: 0.9651 - val_loss: 0.1086 - val_acc: 0.9668\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0950 - acc: 0.9714 - val_loss: 0.0893 - val_acc: 0.9722\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0754 - acc: 0.9770 - val_loss: 0.0876 - val_acc: 0.9735\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0676 - acc: 0.9793 - val_loss: 0.0889 - val_acc: 0.9727\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0557 - acc: 0.9821 - val_loss: 0.0924 - val_acc: 0.9737\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0486 - acc: 0.9849 - val_loss: 0.0860 - val_acc: 0.9763\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0434 - acc: 0.9863 - val_loss: 0.0847 - val_acc: 0.9769\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0383 - acc: 0.9877 - val_loss: 0.0806 - val_acc: 0.9778\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0369 - acc: 0.9880 - val_loss: 0.0833 - val_acc: 0.9761\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0315 - acc: 0.9893 - val_loss: 0.0894 - val_acc: 0.9764\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0296 - acc: 0.9896 - val_loss: 0.0903 - val_acc: 0.9762\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0262 - acc: 0.9912 - val_loss: 0.0898 - val_acc: 0.9766\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0251 - acc: 0.9911 - val_loss: 0.0953 - val_acc: 0.9758\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0227 - acc: 0.9923 - val_loss: 0.0953 - val_acc: 0.9775\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0214 - acc: 0.9930 - val_loss: 0.0862 - val_acc: 0.9769\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0192 - acc: 0.9934 - val_loss: 0.0944 - val_acc: 0.9780\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0223 - acc: 0.9926 - val_loss: 0.0927 - val_acc: 0.9783\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0175 - acc: 0.9943 - val_loss: 0.0937 - val_acc: 0.9787\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = Adam() #optimizer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,batch_size=128, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9888/10000 [============================>.] - ETA: 0s\n",
      "Loss: 0.08, Accuracy: 97.81%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.3059 - acc: 0.9058 - val_loss: 0.1345 - val_acc: 0.9593\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1494 - acc: 0.9543 - val_loss: 0.1060 - val_acc: 0.9688\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1180 - acc: 0.9641 - val_loss: 0.0977 - val_acc: 0.9711\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0978 - acc: 0.9701 - val_loss: 0.0895 - val_acc: 0.9741\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0870 - acc: 0.9726 - val_loss: 0.0875 - val_acc: 0.9726\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0770 - acc: 0.9760 - val_loss: 0.0887 - val_acc: 0.9735\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0689 - acc: 0.9782 - val_loss: 0.0879 - val_acc: 0.9722\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0642 - acc: 0.9790 - val_loss: 0.0841 - val_acc: 0.9759\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0584 - acc: 0.9818 - val_loss: 0.0825 - val_acc: 0.9758\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0563 - acc: 0.9821 - val_loss: 0.0808 - val_acc: 0.9767\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0519 - acc: 0.9831 - val_loss: 0.0813 - val_acc: 0.9766\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0477 - acc: 0.9840 - val_loss: 0.0843 - val_acc: 0.9760\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0458 - acc: 0.9853 - val_loss: 0.0856 - val_acc: 0.9775\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0438 - acc: 0.9862 - val_loss: 0.0848 - val_acc: 0.9765\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0387 - acc: 0.9875 - val_loss: 0.0833 - val_acc: 0.9770\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0372 - acc: 0.9878 - val_loss: 0.0807 - val_acc: 0.9788\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0357 - acc: 0.9880 - val_loss: 0.0878 - val_acc: 0.9784\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0356 - acc: 0.9882 - val_loss: 0.0846 - val_acc: 0.9784\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0360 - acc: 0.9881 - val_loss: 0.0857 - val_acc: 0.9780\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0318 - acc: 0.9894 - val_loss: 0.0925 - val_acc: 0.9760\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_shape=(784,)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train, Y_train,batch_size=128, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s     \n",
      "\n",
      "Loss: 0.09, Accuracy: 97.72%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model2.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.3573 - acc: 0.8896 - val_loss: 0.1514 - val_acc: 0.9559\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1921 - acc: 0.9434 - val_loss: 0.1178 - val_acc: 0.9657\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1526 - acc: 0.9543 - val_loss: 0.1013 - val_acc: 0.9696\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1325 - acc: 0.9601 - val_loss: 0.0961 - val_acc: 0.9720\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1222 - acc: 0.9629 - val_loss: 0.0943 - val_acc: 0.9722\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1096 - acc: 0.9665 - val_loss: 0.0871 - val_acc: 0.9750\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1033 - acc: 0.9682 - val_loss: 0.0874 - val_acc: 0.9753\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0953 - acc: 0.9692 - val_loss: 0.0875 - val_acc: 0.9745\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0873 - acc: 0.9735 - val_loss: 0.0858 - val_acc: 0.9762\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0846 - acc: 0.9726 - val_loss: 0.0884 - val_acc: 0.9748\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0790 - acc: 0.9748 - val_loss: 0.0847 - val_acc: 0.9757\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0792 - acc: 0.9748 - val_loss: 0.0835 - val_acc: 0.9777\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0744 - acc: 0.9765 - val_loss: 0.0851 - val_acc: 0.9769\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0707 - acc: 0.9771 - val_loss: 0.0837 - val_acc: 0.9779\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0682 - acc: 0.9789 - val_loss: 0.0836 - val_acc: 0.9767\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0653 - acc: 0.9785 - val_loss: 0.0842 - val_acc: 0.9776\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0641 - acc: 0.9793 - val_loss: 0.0877 - val_acc: 0.9774\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0608 - acc: 0.9798 - val_loss: 0.0871 - val_acc: 0.9770\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0588 - acc: 0.9806 - val_loss: 0.0855 - val_acc: 0.9776\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0573 - acc: 0.9821 - val_loss: 0.0910 - val_acc: 0.9773\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(128, input_shape=(784,)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "model3.summary()\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train, Y_train,batch_size=128, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9312/10000 [==========================>...] - ETA: 0s\n",
      "Loss: 0.08, Accuracy: 97.81%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model3.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.4121 - acc: 0.8748 - val_loss: 0.1575 - val_acc: 0.9535\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2355 - acc: 0.9319 - val_loss: 0.1306 - val_acc: 0.9635\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1965 - acc: 0.9426 - val_loss: 0.1197 - val_acc: 0.9665\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1742 - acc: 0.9491 - val_loss: 0.1084 - val_acc: 0.9689\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1603 - acc: 0.9520 - val_loss: 0.1107 - val_acc: 0.9684\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1457 - acc: 0.9562 - val_loss: 0.1023 - val_acc: 0.9700\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1399 - acc: 0.9577 - val_loss: 0.0981 - val_acc: 0.9718\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1306 - acc: 0.9598 - val_loss: 0.0981 - val_acc: 0.9714\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1254 - acc: 0.9614 - val_loss: 0.0974 - val_acc: 0.9717\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1166 - acc: 0.9644 - val_loss: 0.0918 - val_acc: 0.9736\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1139 - acc: 0.9657 - val_loss: 0.0952 - val_acc: 0.9730\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1080 - acc: 0.9666 - val_loss: 0.0938 - val_acc: 0.9738\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1056 - acc: 0.9667 - val_loss: 0.0878 - val_acc: 0.9758\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1032 - acc: 0.9682 - val_loss: 0.0901 - val_acc: 0.9759\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0994 - acc: 0.9685 - val_loss: 0.0900 - val_acc: 0.9753\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0956 - acc: 0.9707 - val_loss: 0.0872 - val_acc: 0.9763\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0953 - acc: 0.9695 - val_loss: 0.0871 - val_acc: 0.9755\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0895 - acc: 0.9723 - val_loss: 0.0915 - val_acc: 0.9751\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0897 - acc: 0.9717 - val_loss: 0.0867 - val_acc: 0.9762\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.0862 - acc: 0.9722 - val_loss: 0.0968 - val_acc: 0.9735\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(128, input_shape=(784,)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.4))\n",
    "model4.add(Dense(128))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.4))\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n",
    "model4.summary()\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history4 = model4.fit(X_train, Y_train,batch_size=128, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9408/10000 [===========================>..] - ETA: 0s\n",
      "Loss: 0.09, Accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model4.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.5201 - acc: 0.8416 - val_loss: 0.1900 - val_acc: 0.9463\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.3115 - acc: 0.9088 - val_loss: 0.1605 - val_acc: 0.9535\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2701 - acc: 0.9217 - val_loss: 0.1434 - val_acc: 0.9587\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2377 - acc: 0.9301 - val_loss: 0.1309 - val_acc: 0.9633\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2203 - acc: 0.9347 - val_loss: 0.1268 - val_acc: 0.9625\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2086 - acc: 0.9397 - val_loss: 0.1232 - val_acc: 0.9663\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1987 - acc: 0.9408 - val_loss: 0.1179 - val_acc: 0.9664\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1879 - acc: 0.9442 - val_loss: 0.1113 - val_acc: 0.9684\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1809 - acc: 0.9459 - val_loss: 0.1110 - val_acc: 0.9677\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1736 - acc: 0.9484 - val_loss: 0.1095 - val_acc: 0.9689\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1705 - acc: 0.9494 - val_loss: 0.1089 - val_acc: 0.9688\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1657 - acc: 0.9508 - val_loss: 0.1053 - val_acc: 0.9696\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1588 - acc: 0.9520 - val_loss: 0.1019 - val_acc: 0.9703\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1540 - acc: 0.9545 - val_loss: 0.1076 - val_acc: 0.9688\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1499 - acc: 0.9540 - val_loss: 0.1043 - val_acc: 0.9703\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1459 - acc: 0.9561 - val_loss: 0.1018 - val_acc: 0.9704\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1445 - acc: 0.9567 - val_loss: 0.0998 - val_acc: 0.9724\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1416 - acc: 0.9570 - val_loss: 0.1030 - val_acc: 0.9712\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1360 - acc: 0.9595 - val_loss: 0.1022 - val_acc: 0.9707\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1363 - acc: 0.9578 - val_loss: 0.1018 - val_acc: 0.9721\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(128, input_shape=(784,)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(128))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(10))\n",
    "model5.add(Activation('softmax'))\n",
    "model5.summary()\n",
    "\n",
    "model5.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history5 = model5.fit(X_train, Y_train,batch_size=128, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9056/10000 [==========================>...] - ETA: 0s\n",
      "Loss: 0.09, Accuracy: 97.12%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model5.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282.0\n",
      "Trainable params: 118,282.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s - loss: 0.6520 - acc: 0.7935 - val_loss: 0.2283 - val_acc: 0.9361\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.4108 - acc: 0.8816 - val_loss: 0.1897 - val_acc: 0.9465\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.3629 - acc: 0.8937 - val_loss: 0.1705 - val_acc: 0.9535\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.3287 - acc: 0.9054 - val_loss: 0.1590 - val_acc: 0.9581\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.3071 - acc: 0.9106 - val_loss: 0.1568 - val_acc: 0.9583\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2911 - acc: 0.9150 - val_loss: 0.1528 - val_acc: 0.9578\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2848 - acc: 0.9180 - val_loss: 0.1414 - val_acc: 0.9601\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2696 - acc: 0.9220 - val_loss: 0.1365 - val_acc: 0.9627\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2677 - acc: 0.9225 - val_loss: 0.1295 - val_acc: 0.9644\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2598 - acc: 0.9241 - val_loss: 0.1304 - val_acc: 0.9648\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2561 - acc: 0.9264 - val_loss: 0.1270 - val_acc: 0.9637\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2443 - acc: 0.9291 - val_loss: 0.1270 - val_acc: 0.9638\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2442 - acc: 0.9285 - val_loss: 0.1263 - val_acc: 0.9645\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2371 - acc: 0.9312 - val_loss: 0.1236 - val_acc: 0.9646\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2284 - acc: 0.9336 - val_loss: 0.1222 - val_acc: 0.9642\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2239 - acc: 0.9360 - val_loss: 0.1189 - val_acc: 0.9659\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2229 - acc: 0.9337 - val_loss: 0.1160 - val_acc: 0.9669\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2221 - acc: 0.9346 - val_loss: 0.1156 - val_acc: 0.9687\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2165 - acc: 0.9376 - val_loss: 0.1203 - val_acc: 0.9662\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2163 - acc: 0.9361 - val_loss: 0.1176 - val_acc: 0.9658\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(128, input_shape=(784,)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Dropout(0.6))\n",
    "model6.add(Dense(128))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Dropout(0.6))\n",
    "model6.add(Dense(10))\n",
    "model6.add(Activation('softmax'))\n",
    "model6.summary()\n",
    "\n",
    "model6.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history6 = model6.fit(X_train, Y_train,batch_size=128, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9216/10000 [==========================>...] - ETA: 0s\n",
      "Loss: 0.12, Accuracy: 96.65%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model6.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.97809999999999997,\n",
       " 0.97719999999999996,\n",
       " 0.97809999999999997,\n",
       " 0.97519999999999996,\n",
       " 0.97119999999999995,\n",
       " 0.96650000000000003]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropouts=[0.1,0.2,0.3,0.4,0.5,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkDjnnCsXDxLnnHPl8v8BhrWLmlCJQEEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4eedc496d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(dropouts,accuracies)\n",
    "\n",
    "plt.title('dropouts accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('dropout')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

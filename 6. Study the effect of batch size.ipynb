{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the effect of batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have studied the effect of different batch size. I noticed that the increasing the batch size improves the accuracy but increasing too much also will also degrade the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracies=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 55,050.0\n",
      "Trainable params: 55,050.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s - loss: 0.5269 - acc: 0.8395 - val_loss: 0.1909 - val_acc: 0.9453\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2794 - acc: 0.9184 - val_loss: 0.1434 - val_acc: 0.9584\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2318 - acc: 0.9325 - val_loss: 0.1475 - val_acc: 0.9557\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.2058 - acc: 0.9404 - val_loss: 0.1234 - val_acc: 0.9624\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1837 - acc: 0.9461 - val_loss: 0.1148 - val_acc: 0.9653\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1701 - acc: 0.9478 - val_loss: 0.1166 - val_acc: 0.9647\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1611 - acc: 0.9523 - val_loss: 0.1089 - val_acc: 0.9688\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1550 - acc: 0.9544 - val_loss: 0.1047 - val_acc: 0.9684\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1476 - acc: 0.9553 - val_loss: 0.1041 - val_acc: 0.9718\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 6s - loss: 0.1407 - acc: 0.9575 - val_loss: 0.1052 - val_acc: 0.9705\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1405 - acc: 0.9570 - val_loss: 0.0998 - val_acc: 0.9702\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1357 - acc: 0.9585 - val_loss: 0.0969 - val_acc: 0.9716\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1326 - acc: 0.9597 - val_loss: 0.0992 - val_acc: 0.9733\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1217 - acc: 0.9621 - val_loss: 0.1052 - val_acc: 0.9720\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1287 - acc: 0.9604 - val_loss: 0.1023 - val_acc: 0.9717\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1230 - acc: 0.9625 - val_loss: 0.0970 - val_acc: 0.9743\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1210 - acc: 0.9634 - val_loss: 0.1020 - val_acc: 0.9702\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1187 - acc: 0.9633 - val_loss: 0.0979 - val_acc: 0.9738\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1159 - acc: 0.9646 - val_loss: 0.1044 - val_acc: 0.9712\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s - loss: 0.1120 - acc: 0.9649 - val_loss: 0.1030 - val_acc: 0.9713\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "OPTIMIZER = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,batch_size=32, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9536/10000 [===========================>..] - ETA:  - ETA: 0s\n",
      "Loss: 0.10, Accuracy: 96.97%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 55,050.0\n",
      "Trainable params: 55,050.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.5991 - acc: 0.8156 - val_loss: 0.2135 - val_acc: 0.9383\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.3013 - acc: 0.9117 - val_loss: 0.1661 - val_acc: 0.9524\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2486 - acc: 0.9262 - val_loss: 0.1404 - val_acc: 0.9598\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.2206 - acc: 0.9344 - val_loss: 0.1247 - val_acc: 0.9643\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1993 - acc: 0.9403 - val_loss: 0.1229 - val_acc: 0.9647\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1850 - acc: 0.9456 - val_loss: 0.1176 - val_acc: 0.9661\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1753 - acc: 0.9467 - val_loss: 0.1110 - val_acc: 0.9684\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1650 - acc: 0.9499 - val_loss: 0.1106 - val_acc: 0.9685\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1593 - acc: 0.9522 - val_loss: 0.1088 - val_acc: 0.9686\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1549 - acc: 0.9528 - val_loss: 0.1077 - val_acc: 0.9686\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1448 - acc: 0.9552 - val_loss: 0.1059 - val_acc: 0.9692\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1444 - acc: 0.9562 - val_loss: 0.1035 - val_acc: 0.9705\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1412 - acc: 0.9565 - val_loss: 0.0981 - val_acc: 0.9720\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1373 - acc: 0.9592 - val_loss: 0.1043 - val_acc: 0.9708\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1321 - acc: 0.9598 - val_loss: 0.1053 - val_acc: 0.9696\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1272 - acc: 0.9600 - val_loss: 0.0996 - val_acc: 0.9716\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1254 - acc: 0.9607 - val_loss: 0.1010 - val_acc: 0.9719\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1262 - acc: 0.9609 - val_loss: 0.1056 - val_acc: 0.9710\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1193 - acc: 0.9625 - val_loss: 0.0945 - val_acc: 0.9732\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.1239 - acc: 0.9612 - val_loss: 0.1004 - val_acc: 0.9712\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(64, input_shape=(784,)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.summary()\n",
    "\n",
    "OPTIMIZER = Adam()\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train, Y_train,batch_size=64, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9728/10000 [============================>.] - ETA: 0s\n",
      "Loss: 0.10, Accuracy: 97.19%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model2.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 55,050.0\n",
      "Trainable params: 55,050.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 3s - loss: 0.7051 - acc: 0.7806 - val_loss: 0.2434 - val_acc: 0.9292\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.3479 - acc: 0.8984 - val_loss: 0.1884 - val_acc: 0.9470\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2822 - acc: 0.9176 - val_loss: 0.1612 - val_acc: 0.9544\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2413 - acc: 0.9295 - val_loss: 0.1500 - val_acc: 0.9588\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2207 - acc: 0.9331 - val_loss: 0.1373 - val_acc: 0.9605\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.2007 - acc: 0.9408 - val_loss: 0.1313 - val_acc: 0.9619\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1839 - acc: 0.9447 - val_loss: 0.1238 - val_acc: 0.9630\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1790 - acc: 0.9458 - val_loss: 0.1257 - val_acc: 0.9641\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1658 - acc: 0.9507 - val_loss: 0.1164 - val_acc: 0.9662\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1578 - acc: 0.9522 - val_loss: 0.1095 - val_acc: 0.9686\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1504 - acc: 0.9551 - val_loss: 0.1124 - val_acc: 0.9679\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1472 - acc: 0.9551 - val_loss: 0.1065 - val_acc: 0.9697\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1404 - acc: 0.9572 - val_loss: 0.1042 - val_acc: 0.9710\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1368 - acc: 0.9581 - val_loss: 0.1124 - val_acc: 0.9684\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1343 - acc: 0.9590 - val_loss: 0.1035 - val_acc: 0.9706\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1276 - acc: 0.9604 - val_loss: 0.0993 - val_acc: 0.9712\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1239 - acc: 0.9613 - val_loss: 0.0986 - val_acc: 0.9719\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1212 - acc: 0.9622 - val_loss: 0.1038 - val_acc: 0.9703\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1182 - acc: 0.9632 - val_loss: 0.0983 - val_acc: 0.9734\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.1186 - acc: 0.9637 - val_loss: 0.1001 - val_acc: 0.9722\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(64, input_shape=(784,)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(64))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "model3.summary()\n",
    "\n",
    "OPTIMIZER = Adam()\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train, Y_train,batch_size=128, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9824/10000 [============================>.] - ETA: 0s\n",
      "Loss: 0.11, Accuracy: 97.01%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model3.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 55,050.0\n",
      "Trainable params: 55,050.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s - loss: 0.8835 - acc: 0.7207 - val_loss: 0.2836 - val_acc: 0.9198\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.3950 - acc: 0.8850 - val_loss: 0.2120 - val_acc: 0.9393\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.3151 - acc: 0.9082 - val_loss: 0.1836 - val_acc: 0.9467\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2763 - acc: 0.9195 - val_loss: 0.1628 - val_acc: 0.9533\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2450 - acc: 0.9291 - val_loss: 0.1447 - val_acc: 0.9579\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2264 - acc: 0.9337 - val_loss: 0.1390 - val_acc: 0.9595\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2097 - acc: 0.9386 - val_loss: 0.1307 - val_acc: 0.9620\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2003 - acc: 0.9404 - val_loss: 0.1248 - val_acc: 0.9642\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1860 - acc: 0.9447 - val_loss: 0.1212 - val_acc: 0.9658\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1808 - acc: 0.9464 - val_loss: 0.1169 - val_acc: 0.9657\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1713 - acc: 0.9484 - val_loss: 0.1150 - val_acc: 0.9668\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1641 - acc: 0.9505 - val_loss: 0.1120 - val_acc: 0.9662\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1553 - acc: 0.9544 - val_loss: 0.1082 - val_acc: 0.9693\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1529 - acc: 0.9530 - val_loss: 0.1118 - val_acc: 0.9691\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1519 - acc: 0.9551 - val_loss: 0.1068 - val_acc: 0.9690\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1454 - acc: 0.9561 - val_loss: 0.1066 - val_acc: 0.9692\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1378 - acc: 0.9571 - val_loss: 0.1082 - val_acc: 0.9695\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1363 - acc: 0.9594 - val_loss: 0.1037 - val_acc: 0.9698\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1347 - acc: 0.9585 - val_loss: 0.1052 - val_acc: 0.9705\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1310 - acc: 0.9600 - val_loss: 0.1011 - val_acc: 0.9712\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(64, input_shape=(784,)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(64))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.3))\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n",
    "model4.summary()\n",
    "\n",
    "OPTIMIZER = Adam()\n",
    "model4.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history4 = model4.fit(X_train, Y_train,batch_size=256, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s\n",
      "Loss: 0.10, Accuracy: 96.98%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model4.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 55,050.0\n",
      "Trainable params: 55,050.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s - loss: 1.1762 - acc: 0.6157 - val_loss: 0.3740 - val_acc: 0.9009\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.4937 - acc: 0.8532 - val_loss: 0.2591 - val_acc: 0.9247\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.3926 - acc: 0.8856 - val_loss: 0.2206 - val_acc: 0.9362\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.3344 - acc: 0.9003 - val_loss: 0.1931 - val_acc: 0.9448\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2995 - acc: 0.9123 - val_loss: 0.1752 - val_acc: 0.9482\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2730 - acc: 0.9200 - val_loss: 0.1608 - val_acc: 0.9534\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2546 - acc: 0.9248 - val_loss: 0.1509 - val_acc: 0.9577\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2366 - acc: 0.9288 - val_loss: 0.1425 - val_acc: 0.9601\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2196 - acc: 0.9350 - val_loss: 0.1395 - val_acc: 0.9603\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.2100 - acc: 0.9386 - val_loss: 0.1364 - val_acc: 0.9601\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1997 - acc: 0.9405 - val_loss: 0.1256 - val_acc: 0.9641\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1924 - acc: 0.9433 - val_loss: 0.1234 - val_acc: 0.9649\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1838 - acc: 0.9466 - val_loss: 0.1216 - val_acc: 0.9665\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1737 - acc: 0.9490 - val_loss: 0.1159 - val_acc: 0.9668\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1677 - acc: 0.9509 - val_loss: 0.1147 - val_acc: 0.9676\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1672 - acc: 0.9502 - val_loss: 0.1125 - val_acc: 0.9675\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1586 - acc: 0.9518 - val_loss: 0.1092 - val_acc: 0.9678\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1586 - acc: 0.9530 - val_loss: 0.1086 - val_acc: 0.9679\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1525 - acc: 0.9537 - val_loss: 0.1100 - val_acc: 0.9683\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s - loss: 0.1446 - acc: 0.9560 - val_loss: 0.1049 - val_acc: 0.9692\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(64, input_shape=(784,)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Dense(64))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Dense(10))\n",
    "model5.add(Activation('softmax'))\n",
    "model5.summary()\n",
    "\n",
    "OPTIMIZER = Adam()\n",
    "model5.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "history5 = model5.fit(X_train, Y_train,batch_size=512, epochs=20,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "Loss: 0.10, Accuracy: 96.93%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "loss, accuracy = model5.evaluate(X_test, Y_test)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96970000000000001,\n",
       " 0.97189999999999999,\n",
       " 0.97009999999999996,\n",
       " 0.9698,\n",
       " 0.96930000000000005]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=[32,64,128,256,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnWR7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbb325f5208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(batch_size,accuracies)\n",
    "\n",
    "plt.title('batch size accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('batch size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
